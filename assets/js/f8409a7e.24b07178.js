"use strict";(self.webpackChunkgai_doc=self.webpackChunkgai_doc||[]).push([[988],{604:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var r=n(7624),t=n(2172);const s={id:"intro",title:"Introduction",slug:"/"},o=void 0,a={id:"intro",title:"Introduction",description:"Gai aims to adapt the powerful features of proprietary language models",source:"@site/docs/intro.mdx",sourceDirName:".",slug:"/",permalink:"/gai/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"intro",title:"Introduction",slug:"/"},sidebar:"tutorialSidebar",next:{title:"gai-gen-intro",permalink:"/gai/local-llm/gai-gen-intro"}},l={},c=[{value:"Models",id:"models",level:2},{value:"Libraries",id:"libraries",level:2}];function d(e){const i={a:"a",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.M)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Gai"})," aims to adapt the powerful features of proprietary language models\ninto a library suite for use on local machines with open-source models. By focusing\non specific, high-utility aspects of language model applications instead of a one-size-fits-all\nframework, Gai facilitates easier and faster development of large language model\napplications. It does this by optimizing the design of the library for a select number\nof open-source language models that can serve as viable alternatives to proprietary\nones."]}),"\n",(0,r.jsx)(i.h2,{id:"models",children:"Models"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Gai"})," supports calling both proprietary and open-source models for the following features:"]}),"\n",(0,r.jsxs)("table",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{children:"Feature"}),(0,r.jsx)("th",{children:"Proprietary"}),(0,r.jsx)("th",{children:"Open Source"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsxs)("td",{children:["Text-to-Text (TTT):",(0,r.jsxs)("ul",{children:[(0,r.jsx)("li",{children:"chat completion"}),(0,r.jsx)("li",{children:"long context"}),(0,r.jsx)("li",{children:"function call"})]})]}),(0,r.jsx)("td",{children:"OpenAI GPT-4"}),(0,r.jsxs)("td",{children:["Mistral7b (8k)",(0,r.jsx)("br",{}),"Mistral7b (128k)"]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:"Speech-to-Text (TTT)"}),(0,r.jsx)("td",{children:"OpenAI Whisper"}),(0,r.jsx)("td",{children:"OpenAI Whisper (Open Source)"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:"Text-to-Speech (TTS)"}),(0,r.jsx)("td",{children:"OpenAI Speech"}),(0,r.jsx)("td",{children:"Coqui-TTS"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:"Image-to-Text (ITT)"}),(0,r.jsx)("td",{children:"OpenAI Vision"}),(0,r.jsx)("td",{children:"Llava7b"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:"Retrieval-Augmented-Generation (RAG)"}),(0,r.jsx)("td",{children:"OpenAI Ada"}),(0,r.jsx)("td",{children:"Instructor Embedding"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:"Text-to-Code (TTC)"}),(0,r.jsx)("td",{children:"Code Interpreter"}),(0,r.jsx)("td",{children:"DeepSeek Coder"})]})]}),"\n",(0,r.jsx)(i.h2,{id:"libraries",children:"Libraries"}),"\n",(0,r.jsx)(i.p,{children:"There are two main libraries in the Gai suite:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"[Gai/Gen]"}),"(",(0,r.jsx)(i.a,{href:"https://github.com/gai-labs/gai/gen",children:"https://github.com/gai-labs/gai/gen"}),"): The focus of this library is to support local LLMs. It is a singleton wrapper designed to interface with only one model at a time designed on run on a local machine. Typically, you will then run this as an API service. We shall call this single model services as ",(0,r.jsx)(i.strong,{children:"Gai Instances"}),". For more complex scenarios, such as developing multi-modal application or multi-agent chatbot, you may require a cluster of Gai Instances. You can simply deploy your own cluster through a cloud provider or use Gai-AIO, a service from GaiLabs for hosting and managing cluster of Gai Instances."]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"[Gai/Lib]"}),"(",(0,r.jsx)(i.a,{href:"https://github.com/gai-labs/gai/lib",children:"https://github.com/gai-labs/gai/lib"}),"): The focus of this library is to provide client-side access to propretary models and Gai Instances. You can choose to use Gai/Lib in an openai-compatible manner or use the Gai/Lib unified interface that is simpler and easier for access across all supported models."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.strong,{children:"Note:"})}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsx)(i.li,{children:"This is not an end-to-end framework for llm application development. If you require a comprehensive framework, you may want to consider using LangChain."}),"\n",(0,r.jsx)(i.li,{children:"This is not a generic library for all llm models. If you require a generic library, you may want to consider using HuggingFace's Transformers."}),"\n",(0,r.jsx)(i.li,{children:"The definition of open source is rather broad. In this context, it simply refers to models that are not proprietary. You are advised to check the licensing of the underlying models you use."}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,t.M)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},2172:(e,i,n)=>{n.d(i,{I:()=>a,M:()=>o});var r=n(1504);const t={},s=r.createContext(t);function o(e){const i=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:i},e.children)}}}]);