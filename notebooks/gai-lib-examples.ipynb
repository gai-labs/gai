{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gai/Lib: Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Text (TTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text generation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "\n",
    "# Mistral7B\n",
    "print(\"> Mistral-7B\")\n",
    "for chunk in ggg(category=\"ttt\",messages=\"user: Tell me a one paragraph story\\nassistant:\"):\n",
    "    print(chunk.decode(),end=\"\",flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "\n",
    "# GPT4\n",
    "print(\"> OpenAI\")\n",
    "for chunk in ggg(category=\"ttt\",generator=\"gpt-4\",messages=\"user: Tell me a one paragraph story\\nassistant:\"):\n",
    "    print(chunk.decode(),end=\"\",flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"> OpenAI API\")\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise Exception(\n",
    "        \"OPENAI_API_KEY not found in environment variables\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"}],\n",
    "    stream=True,\n",
    "    max_tokens=100,\n",
    ")\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTT With Function Call\n",
    "\n",
    "OpenAPI provides a powerful feature for its API known as Function Calling. Essentially, this is a mechanism for the LLM to seek external assistance when it encounters limitations in its text generation capabilities. It does this by returning a string that emulates the calling of a function, based on the function description provided by the user.\n",
    "\n",
    "In the following example, we demonstrate function calling  being to an open source model using Mistral7b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "\n",
    "# Mistral7B\n",
    "print(\"> Mistral-7B\")\n",
    "response = ggg(category=\"ttt\",\n",
    "    messages=\"user: What is today's date?\\nassistant:\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"gg\",\n",
    "                \"description\": \"The 'gg' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"search_query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"search_query\"]\n",
    "                }\n",
    "            }\n",
    "        }                   \n",
    "    ],\n",
    "    stream=False)\n",
    "print(response.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "\n",
    "# OpenAI\n",
    "print(\"> OpenAI\")\n",
    "response = ggg(category=\"ttt\",\n",
    "                generator=\"gpt-4\",\n",
    "               messages=\"user: Who is the current president of Singapore?\\nassistant:\",\n",
    "                tools=[\n",
    "                    {\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": \"gg\",\n",
    "                            \"description\": \"The 'gg' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "                            \"parameters\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"search_query\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"search_query\"]\n",
    "                            }\n",
    "                        }\n",
    "                    }                   \n",
    "                ],\n",
    "               stream=False)\n",
    "print(response.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"> OpenAI Original\")\n",
    "import os,json\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise Exception(\n",
    "        \"OPENAI_API_KEY not found in environment variables\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me the latest news on Singapore\"}],\n",
    "    stream=True,\n",
    "    max_tokens=100,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"gg\",\n",
    "                \"description\": \"The 'gg' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"search_query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"search_query\"]\n",
    "                }\n",
    "            }\n",
    "        }                   \n",
    "    ],\n",
    ")\n",
    "tool = {}\n",
    "tool[\"arguments\"]=\"\"\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.tool_calls and chunk.choices[0].delta.tool_calls[0].function.name:\n",
    "        tool[\"name\"] = chunk.choices[0].delta.tool_calls[0].function.name\n",
    "    elif chunk.choices[0].delta.tool_calls and chunk.choices[0].delta.tool_calls[0].function.arguments:\n",
    "        tool[\"arguments\"] += chunk.choices[0].delta.tool_calls[0].function.arguments\n",
    "print(json.dumps(tool, indent=4)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Speech (TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.common.sound_utils import play_audio,save_audio\n",
    "\n",
    "data = {\n",
    "    \"input\": \"The definition of insanity is doing the same thing over and over and expecting different results.\",\n",
    "    \"voice\": None,\n",
    "    \"language\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "response = ggg(\"tts\", **data)\n",
    "play_audio(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai tts\n",
    "response = ggg(\"tts\", generator=\"openai-tts-1\", **data)\n",
    "play_audio(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai original\n",
    "response = client.audio.speech.create(\n",
    "    model='tts-1', input=\"The definition of insanity is doing the same thing over and over and expecting different results.\", voice=\"alloy\")\n",
    "play_audio(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech-to-Text (STT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "with open(\"../gai-lib/tests/lib/stt/today-is-a-wonderful-day.wav\", \"rb\") as f:\n",
    "    play_audio(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "\n",
    "# OpenSource Whisper\n",
    "with open(\"../gai-lib/tests/lib/stt/today-is-a-wonderful-day.wav\", \"rb\") as f:\n",
    "    output = ggg(\"stt\", file=f)\n",
    "    print(output.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Whisper\n",
    "with open(\"../gai-lib/tests/lib/stt/today-is-a-wonderful-day.wav\", \"rb\") as f:\n",
    "    output = ggg(\"stt\", generator=\"openai-whisper\", file=f)\n",
    "    print(output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-to-Text (ITT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.common.image_utils import read_to_base64\n",
    "import os\n",
    "from IPython.display import Image,display\n",
    "image_file = os.path.join(\"../gai-lib/tests/lib/itt\", \"buses.jpeg\")\n",
    "encoded_string = read_to_base64(image_file)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_string}\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "display(Image(image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llava\n",
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG(\"../gai-lib/gai.yml\")\n",
    "\n",
    "print(\"> Llava\")\n",
    "for chunk in ggg(\"itt\",messages=messages,stream=True):\n",
    "    print(chunk.decode(),end=\"\",flush=True)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "print(\"> OpenAI\")\n",
    "for chunk in ggg(category=\"itt\", generator=\"openai-vision\", messages=messages, stream=True, max_tokens=100):\n",
    "    print(chunk.decode(), end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the progress of the indexing status of the remote service by running the following:\n",
    "\n",
    "a) /tests/client/rag/function_test_websocket_forwarder.py\n",
    "\n",
    "b) /tests/client/rag/function_test_websocket_forwarder_listener.py\n",
    "\n",
    "The first script will forward the status of the remote service to the local port.\n",
    "The second script will pull the status from the local port and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 07:31:31 INFO gai.lib.RAGClient:\u001b[32mRAGClient.delete_collection: Deleting collection https://gaiaio.ai/api/gen/v1/rag/collection/demo\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count': 0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete \"demo\" Collection.\n",
    "from gai.lib.RAGClient import RAGClient\n",
    "rag = RAGClient(\"../gai-lib/gai.yml\")\n",
    "rag.delete_collection(\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collections': []}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List Collections\n",
    "from gai.lib.RAGClient import RAGClient\n",
    "rag = RAGClient(\"../gai-lib/gai.yml\")\n",
    "rag.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Listener\n",
    "\n",
    "Before continuing with the following steps, start an external rag_listener to monitor the progress of the indexing status.\n",
    "\n",
    "```bash\n",
    "cd /gai-lib/tests/client/rag\n",
    "python rag_listener.py\n",
    "```\n",
    "\n",
    "#### Start Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_id': 'a7f04c65-5520-4bea-b04b-357ef9996c32'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index 2023 national day speech \n",
    "from gai.lib.GGG import GGG\n",
    "ggg = GGG(\"../gai-lib/gai.yml\")\n",
    "def updater(status):\n",
    "    print(status)\n",
    "\n",
    "data = {\n",
    "    \"collection_name\": \"demo\",\n",
    "    \"file_path\": \"../gai-lib/tests/clients/rag/pm_long_speech_2023.txt\",\n",
    "    \"metadata\": {\"title\": \"2023 National Day Rally Speech\", \n",
    "    \"source\": \"https://www.pmo.gov.sg/Newsroom/national-day-rally-2023\"},\n",
    "}\n",
    "ggg(\"index\", **data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List documents\n",
    "from gai.lib.RAGClient import RAGClient\n",
    "rag = RAGClient(\"../gai-lib/gai.yml\")\n",
    "docs=rag.list_documents(\"demo\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document\n",
    "from gai.lib.RAGClient import RAGClient\n",
    "rag = RAGClient(\"../gai-lib/gai.yml\")\n",
    "rag.get_document(docs['documents'][0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg = GGG((\"../gai-lib/gai.yml\"))\n",
    "\n",
    "data = {\n",
    "    \"collection_name\": \"demo\",\n",
    "    \"query_texts\": \"Who are the young seniors?\",\n",
    "}\n",
    "response = ggg(\"retrieve\", **data)\n",
    "context = response.text\n",
    "question = \"Who are the young seniors?\"\n",
    "answer = ggg(\"ttt\", messages=f\"user: Based on the context below: <context>{context}</context>, answer the question: {question}\\nassistant:\")\n",
    "for chunk in answer:\n",
    "    print(chunk.decode(), end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.lib.GGG import GGG\n",
    "ggg=GGG((\"../gai-lib/gai.yml\"))\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"gg\",\n",
    "            \"description\": \"The 'gg' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag\",\n",
    "            \"description\": \"The 'rag' function is a specialized tool that allows the AI to perform semantic searches on PM Lee Hsien Loong's 2023 National Day Rally. It can be invoked when the AI needs to retrieve facts or information from the speech. This function utilizes advanced Natural Language Processing (NLP) techniques to understand and match the semantic meaning of the user's query with the content of the speech. This is particularly useful when the user's query relates to specific themes, topics, or statements made during the rally.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"[query_1, query_2, query_3]\",\n",
    "                        \"description\": \"An array of search queries to perform a semantic search in the vector database. Each string in the array represents a different way of asking the question. This expands the coverage of the search and increases the chance of finding the best match. For example, instead of using one query like 'economic policies', use multiple variations like ['PM Lee Hsien Loong's economic policies announced at the 2023 National Day Rally', 'What were the economic strategies discussed by PM Lee in 2023 National Day Rally?', 'Economic measures announced by PM Lee in 2023 Rally'].\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# RAG + Function Call\n",
    "import json\n",
    "print(\"> Mistral-7B\")\n",
    "question = \"What did PM Lee say about young seniors?\"\n",
    "\n",
    "messages = [{'role':'user','content':question},{'role':'assistant','content':''}]\n",
    "response = ggg(category=\"ttt\",\n",
    "               messages=messages, \n",
    "               tools=tools,\n",
    "               stream=False,\n",
    "               max_new_tokens=100)\n",
    "result=response.decode()\n",
    "search_query = json.loads(result['arguments'])['search_query'][0]\n",
    "data = {\n",
    "    \"collection_name\": \"demo\",\n",
    "    \"query_texts\": search_query,\n",
    "}\n",
    "response = ggg(\"retrieve\", **data)\n",
    "context = response.text\n",
    "answer = ggg(\"ttt\", messages=f\"user: Based on the context below: <context>{context}</context>, answer the question: {question}\\nassistant:\")\n",
    "for chunk in answer:\n",
    "    print(chunk.decode(), end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete document\n",
    "from gai.lib.RAGClient import RAGClient\n",
    "rag = RAGClient((\"../gai-lib/gai.yml\"))\n",
    "rag.delete_document(docs['documents'][0]['id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
